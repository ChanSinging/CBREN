Namespace(batchSize=8, cuda=True, dataset='datasets/', lr=0.0001, momentum=0.9, nEpochs=2000, resume='', start_epoch=1, step=1000, test_path='dataset/test/', threads=16, validate_path='datasets/validate/', weight_decay=0)
===> Loading datasets
===> Building model
n_pyramids: 1 n_pyramid_cells: (3, 2, 1, 1, 1, 1)
===> Setting GPU
===> Setting Optimizer
===> Training
Epoch=1, lr=0.0001
===> Epoch[1](1/23): Loss: 0.4091456831
===> Epoch[1](2/23): Loss: 0.3863196969
===> Epoch[1](3/23): Loss: 0.3806863725
===> Epoch[1](4/23): Loss: 0.3361514211
===> Epoch[1](5/23): Loss: 0.4024398327
===> Epoch[1](6/23): Loss: 0.3619632721
===> Epoch[1](7/23): Loss: 0.3345957398
===> Epoch[1](8/23): Loss: 0.3337016702
===> Epoch[1](9/23): Loss: 0.2070400715
===> Epoch[1](10/23): Loss: 0.4850289524
===> Epoch[1](11/23): Loss: 0.2794495225
===> Epoch[1](12/23): Loss: 0.4865024686
Traceback (most recent call last):
  File "train_psnr_indication.py", line 314, in <module>
    main()
  File "train_psnr_indication.py", line 161, in main
    train(training_data_loader, optimizer, model, criterion, epoch)
  File "train_psnr_indication.py", line 213, in train
    loss.backward()
  File "/home/pxk/anaconda3/envs/cxy/lib/python3.7/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/pxk/anaconda3/envs/cxy/lib/python3.7/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt