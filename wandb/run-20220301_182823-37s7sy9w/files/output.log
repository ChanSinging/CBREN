Namespace(batchSize=16, cuda=True, dataset='datasets/', lr=0.0001, momentum=0.9, nEpochs=2000, resume='', start_epoch=1, step=1000, test_path='dataset/test/', threads=16, validate_path='datasets/validate/', weight_decay=0)
===> Loading datasets
===> Building model
n_pyramids: 1 n_pyramid_cells: (3, 2, 1, 1, 1, 1)
===> Setting GPU
===> Setting Optimizer
===> Training
Epoch=1, lr=0.0001
===> Epoch[1](1/3750): Loss: 0.4024877548
===> Epoch[1](2/3750): Loss: 0.3932407796
===> Epoch[1](3/3750): Loss: 0.3795540035
===> Epoch[1](4/3750): Loss: 0.3352205455
===> Epoch[1](5/3750): Loss: 0.3829383254
===> Epoch[1](6/3750): Loss: 0.4496806860
===> Epoch[1](7/3750): Loss: 0.4254613221
===> Epoch[1](8/3750): Loss: 0.3457002938
===> Epoch[1](9/3750): Loss: 0.4045540392
===> Epoch[1](10/3750): Loss: 0.3111092150
===> Epoch[1](11/3750): Loss: 0.2973586619
===> Epoch[1](12/3750): Loss: 0.2921689749
===> Epoch[1](13/3750): Loss: 0.3714513481
===> Epoch[1](14/3750): Loss: 0.3430199921
===> Epoch[1](15/3750): Loss: 0.3584272265
===> Epoch[1](16/3750): Loss: 0.2598005533
===> Epoch[1](17/3750): Loss: 0.3349755406
===> Epoch[1](18/3750): Loss: 0.3005594909
===> Epoch[1](19/3750): Loss: 0.3256135285
===> Epoch[1](20/3750): Loss: 0.2409774363
===> Epoch[1](21/3750): Loss: 0.3337261677
===> Epoch[1](22/3750): Loss: 0.3279260099
===> Epoch[1](23/3750): Loss: 0.2632279992
===> Epoch[1](24/3750): Loss: 0.3899686038
===> Epoch[1](25/3750): Loss: 0.3163606822
===> Epoch[1](26/3750): Loss: 0.2554921210
===> Epoch[1](27/3750): Loss: 0.2580475509
===> Epoch[1](28/3750): Loss: 0.3049060702
===> Epoch[1](29/3750): Loss: 0.1918639094
===> Epoch[1](30/3750): Loss: 0.2144485563
===> Epoch[1](31/3750): Loss: 0.1292016357
===> Epoch[1](32/3750): Loss: 0.1616193652
===> Epoch[1](33/3750): Loss: 0.1391187757
===> Epoch[1](34/3750): Loss: 0.0986581817
===> Epoch[1](35/3750): Loss: 0.1136764288
===> Epoch[1](36/3750): Loss: 0.1231313795
===> Epoch[1](37/3750): Loss: 0.1417705268
===> Epoch[1](38/3750): Loss: 0.1232127473
===> Epoch[1](39/3750): Loss: 0.1216415167
===> Epoch[1](40/3750): Loss: 0.1280331165
===> Epoch[1](41/3750): Loss: 0.1123065427
===> Epoch[1](42/3750): Loss: 0.1029020324
===> Epoch[1](43/3750): Loss: 0.0969667286
===> Epoch[1](44/3750): Loss: 0.1079919413
===> Epoch[1](45/3750): Loss: 0.0976805538
===> Epoch[1](46/3750): Loss: 0.1068668291
===> Epoch[1](47/3750): Loss: 0.1166069955
===> Epoch[1](48/3750): Loss: 0.1041196659
===> Epoch[1](49/3750): Loss: 0.0910184979
===> Epoch[1](50/3750): Loss: 0.1071139276
===> Epoch[1](51/3750): Loss: 0.0923575088
===> Epoch[1](52/3750): Loss: 0.1010604426
===> Epoch[1](53/3750): Loss: 0.0960188806
===> Epoch[1](54/3750): Loss: 0.0957004577
===> Epoch[1](55/3750): Loss: 0.0972252935
===> Epoch[1](56/3750): Loss: 0.1034380272
===> Epoch[1](57/3750): Loss: 0.0925730839
===> Epoch[1](58/3750): Loss: 0.0792197585
===> Epoch[1](59/3750): Loss: 0.0930508003
===> Epoch[1](60/3750): Loss: 0.0885553434
===> Epoch[1](61/3750): Loss: 0.0977388769
===> Epoch[1](62/3750): Loss: 0.0928802863
Traceback (most recent call last):
  File "train_psnr_indication.py", line 313, in <module>
    main()
  File "train_psnr_indication.py", line 159, in main
    train(training_data_loader, optimizer, model, criterion, epoch)
  File "train_psnr_indication.py", line 210, in train
    optimizer.zero_grad()
  File "/home/pxk/anaconda3/envs/cxy/lib/python3.7/site-packages/torch/optim/optimizer.py", line 217, in zero_grad
    p.grad.zero_()
KeyboardInterrupt
===> Epoch[1](63/3750): Loss: 0.1020621583